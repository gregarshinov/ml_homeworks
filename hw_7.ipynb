{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from tensorflow.keras.layers import Input, Embedding, Activation, Flatten, Dense\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  data/quora.csv.zip\n",
      "  inflating: quora.csv               \n",
      "  inflating: __MACOSX/._quora.csv    \n"
     ]
    }
   ],
   "source": [
    "!unzip data/quora.csv.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('quora.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, test_texts, train_y, test_y = train_test_split(data.question_text, data.target, test_size=0.1, stratify=data.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tiokenizing texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tk = Tokenizer(num_words=None, char_level=True, oov_token='UNK')\n",
    "tk.fit_on_texts(train_texts)\n",
    "\n",
    "alphabet = \"abcdefghijklmnopqrstuvwxyz0123456789,;.!?:'\\\"/\\\\|_@#$%^&*~`+-=<>()[]{}\"\n",
    "char_dict = {}\n",
    "for i, char in enumerate(alphabet):\n",
    "    char_dict[char] = i + 1\n",
    "\n",
    "\n",
    "tk.word_index = char_dict.copy()\n",
    "\n",
    "tk.word_index[tk.oov_token] = max(char_dict.values()) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert string to index\n",
    "train_sequences = tk.texts_to_sequences(train_texts)\n",
    "test_sequences = tk.texts_to_sequences(test_texts)\n",
    "\n",
    "# Padding\n",
    "train_data = pad_sequences(train_sequences, maxlen = MAX_LEN, padding='post')\n",
    "test_data = pad_sequences(test_sequences, maxlen = MAX_LEN, padding='post')\n",
    "\n",
    "# Convert to numpy array\n",
    "train_data = np.array(train_data, dtype='float32')\n",
    "test_data = np.array(test_data, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "train_classes = to_categorical(train_y)\n",
    "test_classes = to_categorical(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 300)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_3 (Embedding)      (None, 300, 69)           4830      \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 294, 256)          123904    \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 294, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 98, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 92, 256)           459008    \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 92, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 30, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 28, 256)           196864    \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 28, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_21 (Conv1D)           (None, 26, 256)           196864    \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 26, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 24, 256)           196864    \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 24, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 22, 256)           196864    \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 22, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 300)               537900    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 2)                 602       \n",
      "=================================================================\n",
      "Total params: 2,004,000\n",
      "Trainable params: 2,004,000\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# =====================Char CNN=======================\n",
    "# parameter\n",
    "input_size = MAX_LEN\n",
    "vocab_size = len(tk.word_index)\n",
    "embedding_size = 69\n",
    "conv_layers = [[256, 7, 3],\n",
    "               [256, 7, 3],\n",
    "               [256, 3, -1],\n",
    "               [256, 3, -1],\n",
    "               [256, 3, -1],\n",
    "               [256, 3, 3]]\n",
    "\n",
    "fully_connected_layers = [MAX_LEN, MAX_LEN]\n",
    "num_of_classes = 2\n",
    "dropout_p = 0.5\n",
    "optimizer = 'adam'\n",
    "loss = 'binary_crossentropy'\n",
    "\n",
    "# Embedding weights\n",
    "embedding_weights = []  # (70, 69)\n",
    "embedding_weights.append(np.zeros(vocab_size))  # (0, 69)\n",
    "\n",
    "for char, i in tk.word_index.items():  # from index 1 to 69\n",
    "    onehot = np.zeros(vocab_size)\n",
    "    onehot[i - 1] = 1\n",
    "    embedding_weights.append(onehot)\n",
    "\n",
    "embedding_weights = np.array(embedding_weights)\n",
    "print('Load')\n",
    "\n",
    "# Embedding layer Initialization\n",
    "embedding_layer = Embedding(vocab_size + 1,\n",
    "                            embedding_size,\n",
    "                            input_length=input_size,\n",
    "                            weights=[embedding_weights])\n",
    "\n",
    "# Model Construction\n",
    "# Input\n",
    "inputs = Input(shape=(input_size,), name='input', dtype='int64')  # shape=(?, 1014)\n",
    "# Embedding\n",
    "x = embedding_layer(inputs)\n",
    "# Conv\n",
    "for filter_num, filter_size, pooling_size in conv_layers:\n",
    "    x = Conv1D(filter_num, filter_size)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    if pooling_size != -1:\n",
    "        x = MaxPooling1D(pool_size=pooling_size)(x)  # Final shape=(None, 34, 256)\n",
    "x = Flatten()(x)  # (None, 8704)\n",
    "# Fully connected layers\n",
    "for dense_size in fully_connected_layers:\n",
    "    x = Dense(dense_size, activation='relu')(x)  # dense_size == 1024\n",
    "    x = Dropout(dropout_p)(x)\n",
    "# Output Layer\n",
    "predictions = Dense(num_of_classes, activation='softmax')(x)\n",
    "# Build model\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[f1],)  # Adam, categorical_crossentropy\n",
    "model.summary()\n",
    "\n",
    "# Shuffle\n",
    "indices = np.arange(train_data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "x_train = train_data[indices]\n",
    "y_train = train_classes[indices]\n",
    "\n",
    "x_test = test_data\n",
    "y_test = test_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ModelCheckpoint сохраняет лучшие версии моделей\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint('model.weights', # названия файла \n",
    "                                                monitor='val_f1', # за какой метрикой следить\n",
    "                                                verbose=1, # будет печатать что происходит\n",
    "                                                save_weights_only=True, # если нужно только веса сохранить\n",
    "                                                save_best_only=True, # сохранять только лучшие\n",
    "                                                mode='max', # если метрика должна расти, то тут max и min если наоборот\n",
    "                                                save_freq='epoch' # как часто вызывать\n",
    "                                               )\n",
    "\n",
    "# EarlyStopping позволяет автоматически остановить обучение, если качество не улучшается \n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_f1', \n",
    "                                              min_delta=0.01, # какая разница считается как улучшение\n",
    "                                              patience=3, # сколько эпох терпеть отсутствие улучшений\n",
    "                                              verbose=1, \n",
    "                                              mode='max',\n",
    "                                              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.keras import TqdmCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58b56556fa394d8f8f882e2dce79d03b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c127b26b19264c1c911e8aaae36d8281",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=36735.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "36732/36735 [============================>.] - ETA: 0s - loss: 0.9489 - f1: 0.9381\n",
      "Epoch 00001: val_f1 improved from -inf to 0.93813, saving model to model.weights\n",
      "36735/36735 [==============================] - 482s 13ms/step - loss: 0.9489 - f1: 0.9381 - val_loss: 0.9489 - val_f1: 0.9381\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a487e54834d456ea06ba2e7d1c8d82f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=36735.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      "36732/36735 [============================>.] - ETA: 0s - loss: 0.9489 - f1: 0.9381\n",
      "Epoch 00002: val_f1 did not improve from 0.93813\n",
      "36735/36735 [==============================] - 482s 13ms/step - loss: 0.9489 - f1: 0.9381 - val_loss: 0.9489 - val_f1: 0.9381\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e41abd79d066461d80d19e87b4c4f0d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=36735.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      "36732/36735 [============================>.] - ETA: 0s - loss: 0.9489 - f1: 0.9381\n",
      "Epoch 00003: val_f1 did not improve from 0.93813\n",
      "36735/36735 [==============================] - 482s 13ms/step - loss: 0.9489 - f1: 0.9381 - val_loss: 0.9489 - val_f1: 0.9381\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "452af71da9384d64a6c20ff204370e12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=36735.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10\n",
      "  342/36735 [..............................] - ETA: 7:36 - loss: 0.8829 - f1: 0.9424"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-381bcaf45ca7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m           callbacks=[TqdmCallback(verbose=2), checkpoint, early_stop])\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    918\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    919\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    606\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    637\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    640\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          validation_data=(x_test, y_test),\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          callbacks=[TqdmCallback(verbose=2), checkpoint, early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'f1', 'val_loss', 'val_f1'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(model.history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(model.history.history['f1'])\n",
    "plt.plot(model.history.history['val_f1'])\n",
    "plt.title('model f1')\n",
    "plt.ylabel('f1')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, even one epoch of training produces great results. loss: 0.9489 - f1: 0.9381 - val_loss: 0.9489 - val_f1: 0.9381"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
