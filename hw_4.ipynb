{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Home work 4\n",
    "### Grigory Arshinov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1\n",
    "\n",
    "На нескольких алгоритмах кластеризации, умеющих работать с sparse матрицами, проверьте, что работает лучше Count_Vectorizer или TfidfVectorizer (попробуйте выжать максимум из каждого - попробуйте нграммы, символьные нграммы, разные значения max_features и min_df) (3 балла)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.read_csv('data/train.csv')\n",
    "all_data.dropna(subset=['description'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = all_data[[\"title\", \"category_name\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = MorphAnalyzer()\n",
    "class FasterMorphology:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.__morph = MorphAnalyzer()\n",
    "        self.__cache = {}\n",
    "    \n",
    "    def parse(self, word: str):\n",
    "        if word in self.__cache:\n",
    "            return self.__cache[word]\n",
    "        else:\n",
    "            analysis = self.__morph.parse(word)\n",
    "            self.__cache[word] = analysis[0]\n",
    "            return analysis[0]\n",
    "\n",
    "parser = FasterMorphology()\n",
    "\n",
    "def lemmatizer(text):\n",
    "    return [parser.parse(word).normal_form for word in re.findall(r'(?u)\\b\\w\\w+\\b', text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import cluster\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model_cls,\n",
    "                   model_params=None,\n",
    "                   vectorizer_cls=None,\n",
    "                   vectorizer_params=None,\n",
    "                   decomposer_cls=None,\n",
    "                   decomposer_params=None):\n",
    "    if not model_params:\n",
    "        model_params = {}\n",
    "    if vectorizer_cls and not vectorizer_params:\n",
    "        vectorizer_params = {}\n",
    "    text_vectors = vectorizer_cls(**vectorizer_params).fit_transform(data.title)\n",
    "    if decomposer_cls:\n",
    "        if not decomposer_params:\n",
    "            decomposer_params = {}\n",
    "        decomposer = decomposer_cls(**decomposer_params)\n",
    "        text_vectors = decomposer.fit_transform(text_vectors)\n",
    "    model = model_cls(**model_params)\n",
    "    model.fit(text_vectors)\n",
    "    labels = model.labels_\n",
    "    print(\"Silhouette Coefficient: %0.3f\" % metrics.silhouette_score(text_vectors[:10000], labels[:10000]))\n",
    "    print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(data.category_name, labels)) # проверяет, что в кластере объекты одного класса\n",
    "    print(\"Completeness: %0.3f\" % metrics.completeness_score(data.category_name, labels)) # проверяет, что объекты класса только в одном кластере\n",
    "    print(\"V-measure: %0.3f\" % metrics.v_measure_score(data.category_name, labels)) # превращает обе метрики в одну \n",
    "    print(\"Adjusted Rand Index: %0.3f\" % metrics.adjusted_rand_score(data.category_name, labels))\n",
    "    print(\"Adjusted Mutual Information: %0.3f\" % metrics.adjusted_mutual_info_score(data.category_name, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_iterator(parameters):\n",
    "    if not parameters:\n",
    "        yield dict()\n",
    "    else:\n",
    "        key_to_iterate = list(parameters.keys())[0]\n",
    "        next_round_parameters = {p : parameters[p]\n",
    "                    for p in parameters if p != key_to_iterate}\n",
    "        for val in parameters[key_to_iterate]:\n",
    "            for pars in grid_iterator(next_round_parameters):\n",
    "                temp_res = pars\n",
    "                temp_res[key_to_iterate] = val\n",
    "                yield temp_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_prefix(text, prefix):\n",
    "    if text.startswith(prefix):\n",
    "        return text[len(prefix):]\n",
    "    return text\n",
    "\n",
    "def cluster_grid_search(model_cls,\n",
    "                        vectorizer_cls,\n",
    "                        decomposer_cls,\n",
    "                        param_grid,\n",
    "                        fixed_params):\n",
    "    print(\"Model class: %s\" % model_cls)\n",
    "    print(\"Vectorizer class: %s\" % vectorizer_cls)\n",
    "    for params in grid_iterator(param_grid):\n",
    "        params.update(fixed_params)\n",
    "        decomposer_params = {remove_prefix(key, \"dec__\"):value for key, value in params.items() if key.startswith(\"dec__\")}\n",
    "        model_params = {remove_prefix(key, \"model__\"):value for key, value in params.items() if key.startswith(\"model__\")}\n",
    "        vec_params = {remove_prefix(key, \"vec__\"):value for key, value in params.items() if key.startswith(\"vec__\")}\n",
    "        print(\"Params: \", params)\n",
    "        evaluate_model(model_cls=model_cls,\n",
    "                       model_params=model_params,\n",
    "                       vectorizer_cls=vectorizer_cls,\n",
    "                       vectorizer_params=vec_params,\n",
    "                       decomposer_cls=decomposer_cls,\n",
    "                       decomposer_params=decomposer_params or None)\n",
    "        print(\"*\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model class: <class 'sklearn.cluster._kmeans.MiniBatchKMeans'>\n",
      "Vectorizer class: <class 'sklearn.feature_extraction.text.TfidfVectorizer'>\n",
      "Params:  {'vec__analyzer': 'word', 'vec__min_df': 0.02, 'vec__ngram_range': (1, 3), 'model__n_clusters': 2, 'vec__tokenizer': <function lemmatizer at 0x7f9e7614be18>}\n",
      "Silhouette Coefficient: 0.540\n",
      "Homogeneity: 0.082\n",
      "Completeness: 0.931\n",
      "V-measure: 0.150\n",
      "Adjusted Rand Index: 0.028\n",
      "Adjusted Mutual Information: 0.150\n",
      "**************************************************\n",
      "Params:  {'vec__analyzer': 'char', 'vec__min_df': 0.02, 'vec__ngram_range': (1, 3), 'model__n_clusters': 2, 'vec__tokenizer': <function lemmatizer at 0x7f9e7614be18>}\n",
      "Silhouette Coefficient: 0.054\n",
      "Homogeneity: 0.102\n",
      "Completeness: 0.523\n",
      "V-measure: 0.171\n",
      "Adjusted Rand Index: 0.080\n",
      "Adjusted Mutual Information: 0.171\n",
      "**************************************************\n",
      "Params:  {'vec__analyzer': 'word', 'vec__min_df': 0.05, 'vec__ngram_range': (1, 3), 'model__n_clusters': 2, 'vec__tokenizer': <function lemmatizer at 0x7f9e7614be18>}\n",
      "Silhouette Coefficient: 0.787\n",
      "Homogeneity: 0.009\n",
      "Completeness: 0.122\n",
      "V-measure: 0.017\n",
      "Adjusted Rand Index: 0.000\n",
      "Adjusted Mutual Information: 0.017\n",
      "**************************************************\n",
      "Params:  {'vec__analyzer': 'char', 'vec__min_df': 0.05, 'vec__ngram_range': (1, 3), 'model__n_clusters': 2, 'vec__tokenizer': <function lemmatizer at 0x7f9e7614be18>}\n",
      "Silhouette Coefficient: 0.083\n",
      "Homogeneity: 0.095\n",
      "Completeness: 0.515\n",
      "V-measure: 0.161\n",
      "Adjusted Rand Index: 0.069\n",
      "Adjusted Mutual Information: 0.161\n",
      "**************************************************\n",
      "Params:  {'vec__analyzer': 'word', 'vec__min_df': 0.02, 'vec__ngram_range': (1, 2), 'model__n_clusters': 2, 'vec__tokenizer': <function lemmatizer at 0x7f9e7614be18>}\n",
      "Silhouette Coefficient: 0.540\n",
      "Homogeneity: 0.082\n",
      "Completeness: 0.931\n",
      "V-measure: 0.150\n",
      "Adjusted Rand Index: 0.028\n",
      "Adjusted Mutual Information: 0.150\n",
      "**************************************************\n",
      "Params:  {'vec__analyzer': 'char', 'vec__min_df': 0.02, 'vec__ngram_range': (1, 2), 'model__n_clusters': 2, 'vec__tokenizer': <function lemmatizer at 0x7f9e7614be18>}\n",
      "Silhouette Coefficient: 0.062\n",
      "Homogeneity: 0.095\n",
      "Completeness: 0.499\n",
      "V-measure: 0.159\n",
      "Adjusted Rand Index: 0.069\n",
      "Adjusted Mutual Information: 0.159\n",
      "**************************************************\n",
      "Params:  {'vec__analyzer': 'word', 'vec__min_df': 0.05, 'vec__ngram_range': (1, 2), 'model__n_clusters': 2, 'vec__tokenizer': <function lemmatizer at 0x7f9e7614be18>}\n",
      "Silhouette Coefficient: 0.765\n",
      "Homogeneity: 0.022\n",
      "Completeness: 0.280\n",
      "V-measure: 0.041\n",
      "Adjusted Rand Index: 0.000\n",
      "Adjusted Mutual Information: 0.041\n",
      "**************************************************\n",
      "Params:  {'vec__analyzer': 'char', 'vec__min_df': 0.05, 'vec__ngram_range': (1, 2), 'model__n_clusters': 2, 'vec__tokenizer': <function lemmatizer at 0x7f9e7614be18>}\n",
      "Silhouette Coefficient: 0.083\n",
      "Homogeneity: 0.087\n",
      "Completeness: 0.466\n",
      "V-measure: 0.147\n",
      "Adjusted Rand Index: 0.065\n",
      "Adjusted Mutual Information: 0.147\n",
      "**************************************************\n",
      "Params:  {'vec__analyzer': 'word', 'vec__min_df': 0.02, 'vec__ngram_range': (1, 3), 'model__n_clusters': 4, 'vec__tokenizer': <function lemmatizer at 0x7f9e7614be18>}\n",
      "Silhouette Coefficient: 0.633\n",
      "Homogeneity: 0.091\n",
      "Completeness: 0.461\n",
      "V-measure: 0.152\n",
      "Adjusted Rand Index: 0.027\n",
      "Adjusted Mutual Information: 0.152\n",
      "**************************************************\n",
      "Params:  {'vec__analyzer': 'char', 'vec__min_df': 0.02, 'vec__ngram_range': (1, 3), 'model__n_clusters': 4, 'vec__tokenizer': <function lemmatizer at 0x7f9e7614be18>}\n",
      "Silhouette Coefficient: 0.036\n",
      "Homogeneity: 0.117\n",
      "Completeness: 0.278\n",
      "V-measure: 0.164\n",
      "Adjusted Rand Index: 0.071\n",
      "Adjusted Mutual Information: 0.164\n",
      "**************************************************\n",
      "Params:  {'vec__analyzer': 'word', 'vec__min_df': 0.05, 'vec__ngram_range': (1, 3), 'model__n_clusters': 4, 'vec__tokenizer': <function lemmatizer at 0x7f9e7614be18>}\n",
      "Silhouette Coefficient: 0.948\n",
      "Homogeneity: 0.110\n",
      "Completeness: 0.464\n",
      "V-measure: 0.178\n",
      "Adjusted Rand Index: 0.033\n",
      "Adjusted Mutual Information: 0.177\n",
      "**************************************************\n",
      "Params:  {'vec__analyzer': 'char', 'vec__min_df': 0.05, 'vec__ngram_range': (1, 3), 'model__n_clusters': 4, 'vec__tokenizer': <function lemmatizer at 0x7f9e7614be18>}\n",
      "Silhouette Coefficient: 0.069\n",
      "Homogeneity: 0.152\n",
      "Completeness: 0.377\n",
      "V-measure: 0.217\n",
      "Adjusted Rand Index: 0.082\n",
      "Adjusted Mutual Information: 0.217\n",
      "**************************************************\n",
      "Params:  {'vec__analyzer': 'word', 'vec__min_df': 0.02, 'vec__ngram_range': (1, 2), 'model__n_clusters': 4, 'vec__tokenizer': <function lemmatizer at 0x7f9e7614be18>}\n",
      "Silhouette Coefficient: 0.631\n",
      "Homogeneity: 0.129\n",
      "Completeness: 0.630\n",
      "V-measure: 0.215\n",
      "Adjusted Rand Index: 0.044\n",
      "Adjusted Mutual Information: 0.215\n",
      "**************************************************\n",
      "Params:  {'vec__analyzer': 'char', 'vec__min_df': 0.02, 'vec__ngram_range': (1, 2), 'model__n_clusters': 4, 'vec__tokenizer': <function lemmatizer at 0x7f9e7614be18>}\n",
      "Silhouette Coefficient: 0.054\n",
      "Homogeneity: 0.157\n",
      "Completeness: 0.388\n",
      "V-measure: 0.223\n",
      "Adjusted Rand Index: 0.079\n",
      "Adjusted Mutual Information: 0.223\n",
      "**************************************************\n",
      "Params:  {'vec__analyzer': 'word', 'vec__min_df': 0.05, 'vec__ngram_range': (1, 2), 'model__n_clusters': 4, 'vec__tokenizer': <function lemmatizer at 0x7f9e7614be18>}\n",
      "Silhouette Coefficient: 0.948\n",
      "Homogeneity: 0.110\n",
      "Completeness: 0.464\n",
      "V-measure: 0.178\n",
      "Adjusted Rand Index: 0.033\n",
      "Adjusted Mutual Information: 0.177\n",
      "**************************************************\n",
      "Params:  {'vec__analyzer': 'char', 'vec__min_df': 0.05, 'vec__ngram_range': (1, 2), 'model__n_clusters': 4, 'vec__tokenizer': <function lemmatizer at 0x7f9e7614be18>}\n",
      "Silhouette Coefficient: 0.064\n",
      "Homogeneity: 0.153\n",
      "Completeness: 0.371\n",
      "V-measure: 0.217\n",
      "Adjusted Rand Index: 0.084\n",
      "Adjusted Mutual Information: 0.217\n",
      "**************************************************\n",
      "Params:  {'vec__analyzer': 'word', 'vec__min_df': 0.02, 'vec__ngram_range': (1, 3), 'model__n_clusters': 6, 'vec__tokenizer': <function lemmatizer at 0x7f9e7614be18>}\n",
      "Silhouette Coefficient: 0.703\n",
      "Homogeneity: 0.043\n",
      "Completeness: 0.160\n",
      "V-measure: 0.067\n",
      "Adjusted Rand Index: -0.017\n",
      "Adjusted Mutual Information: 0.067\n",
      "**************************************************\n",
      "Params:  {'vec__analyzer': 'char', 'vec__min_df': 0.02, 'vec__ngram_range': (1, 3), 'model__n_clusters': 6, 'vec__tokenizer': <function lemmatizer at 0x7f9e7614be18>}\n",
      "Silhouette Coefficient: 0.061\n",
      "Homogeneity: 0.192\n",
      "Completeness: 0.425\n",
      "V-measure: 0.265\n",
      "Adjusted Rand Index: 0.057\n",
      "Adjusted Mutual Information: 0.264\n",
      "**************************************************\n",
      "Params:  {'vec__analyzer': 'word', 'vec__min_df': 0.05, 'vec__ngram_range': (1, 3), 'model__n_clusters': 6, 'vec__tokenizer': <function lemmatizer at 0x7f9e7614be18>}\n",
      "Silhouette Coefficient: 0.979\n",
      "Homogeneity: 0.131\n",
      "Completeness: 0.507\n",
      "V-measure: 0.208\n",
      "Adjusted Rand Index: 0.034\n",
      "Adjusted Mutual Information: 0.207\n",
      "**************************************************\n",
      "Params:  {'vec__analyzer': 'char', 'vec__min_df': 0.05, 'vec__ngram_range': (1, 3), 'model__n_clusters': 6, 'vec__tokenizer': <function lemmatizer at 0x7f9e7614be18>}\n",
      "Silhouette Coefficient: 0.071\n",
      "Homogeneity: 0.165\n",
      "Completeness: 0.291\n",
      "V-measure: 0.211\n",
      "Adjusted Rand Index: 0.086\n",
      "Adjusted Mutual Information: 0.211\n",
      "**************************************************\n",
      "Params:  {'vec__analyzer': 'word', 'vec__min_df': 0.02, 'vec__ngram_range': (1, 2), 'model__n_clusters': 6, 'vec__tokenizer': <function lemmatizer at 0x7f9e7614be18>}\n",
      "Silhouette Coefficient: 0.736\n",
      "Homogeneity: 0.102\n",
      "Completeness: 0.328\n",
      "V-measure: 0.156\n",
      "Adjusted Rand Index: 0.009\n",
      "Adjusted Mutual Information: 0.156\n",
      "**************************************************\n",
      "Params:  {'vec__analyzer': 'char', 'vec__min_df': 0.02, 'vec__ngram_range': (1, 2), 'model__n_clusters': 6, 'vec__tokenizer': <function lemmatizer at 0x7f9e7614be18>}\n",
      "Silhouette Coefficient: 0.051\n",
      "Homogeneity: 0.156\n",
      "Completeness: 0.284\n",
      "V-measure: 0.201\n",
      "Adjusted Rand Index: 0.078\n",
      "Adjusted Mutual Information: 0.201\n",
      "**************************************************\n",
      "Params:  {'vec__analyzer': 'word', 'vec__min_df': 0.05, 'vec__ngram_range': (1, 2), 'model__n_clusters': 6, 'vec__tokenizer': <function lemmatizer at 0x7f9e7614be18>}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Coefficient: 0.971\n",
      "Homogeneity: 0.125\n",
      "Completeness: 0.493\n",
      "V-measure: 0.200\n",
      "Adjusted Rand Index: 0.034\n",
      "Adjusted Mutual Information: 0.200\n",
      "**************************************************\n",
      "Params:  {'vec__analyzer': 'char', 'vec__min_df': 0.05, 'vec__ngram_range': (1, 2), 'model__n_clusters': 6, 'vec__tokenizer': <function lemmatizer at 0x7f9e7614be18>}\n",
      "Silhouette Coefficient: 0.070\n",
      "Homogeneity: 0.191\n",
      "Completeness: 0.363\n",
      "V-measure: 0.250\n",
      "Adjusted Rand Index: 0.098\n",
      "Adjusted Mutual Information: 0.250\n",
      "**************************************************\n",
      "Params:  {'vec__analyzer': 'word', 'vec__min_df': 0.02, 'vec__ngram_range': (1, 3), 'model__n_clusters': 8, 'vec__tokenizer': <function lemmatizer at 0x7f9e7614be18>}\n",
      "Silhouette Coefficient: 0.794\n",
      "Homogeneity: 0.122\n",
      "Completeness: 0.326\n",
      "V-measure: 0.178\n",
      "Adjusted Rand Index: 0.008\n",
      "Adjusted Mutual Information: 0.177\n",
      "**************************************************\n",
      "Params:  {'vec__analyzer': 'char', 'vec__min_df': 0.02, 'vec__ngram_range': (1, 3), 'model__n_clusters': 8, 'vec__tokenizer': <function lemmatizer at 0x7f9e7614be18>}\n",
      "Silhouette Coefficient: 0.065\n",
      "Homogeneity: 0.205\n",
      "Completeness: 0.329\n",
      "V-measure: 0.252\n",
      "Adjusted Rand Index: 0.081\n",
      "Adjusted Mutual Information: 0.252\n",
      "**************************************************\n",
      "Params:  {'vec__analyzer': 'word', 'vec__min_df': 0.05, 'vec__ngram_range': (1, 3), 'model__n_clusters': 8, 'vec__tokenizer': <function lemmatizer at 0x7f9e7614be18>}\n",
      "Silhouette Coefficient: 0.988\n",
      "Homogeneity: 0.132\n",
      "Completeness: 0.500\n",
      "V-measure: 0.209\n",
      "Adjusted Rand Index: 0.033\n",
      "Adjusted Mutual Information: 0.209\n",
      "**************************************************\n",
      "Params:  {'vec__analyzer': 'char', 'vec__min_df': 0.05, 'vec__ngram_range': (1, 3), 'model__n_clusters': 8, 'vec__tokenizer': <function lemmatizer at 0x7f9e7614be18>}\n",
      "Silhouette Coefficient: 0.083\n",
      "Homogeneity: 0.215\n",
      "Completeness: 0.346\n",
      "V-measure: 0.265\n",
      "Adjusted Rand Index: 0.117\n",
      "Adjusted Mutual Information: 0.264\n",
      "**************************************************\n",
      "Params:  {'vec__analyzer': 'word', 'vec__min_df': 0.02, 'vec__ngram_range': (1, 2), 'model__n_clusters': 8, 'vec__tokenizer': <function lemmatizer at 0x7f9e7614be18>}\n",
      "Silhouette Coefficient: 0.809\n",
      "Homogeneity: 0.158\n",
      "Completeness: 0.401\n",
      "V-measure: 0.227\n",
      "Adjusted Rand Index: 0.018\n",
      "Adjusted Mutual Information: 0.226\n",
      "**************************************************\n",
      "Params:  {'vec__analyzer': 'char', 'vec__min_df': 0.02, 'vec__ngram_range': (1, 2), 'model__n_clusters': 8, 'vec__tokenizer': <function lemmatizer at 0x7f9e7614be18>}\n",
      "Silhouette Coefficient: 0.053\n",
      "Homogeneity: 0.204\n",
      "Completeness: 0.322\n",
      "V-measure: 0.250\n",
      "Adjusted Rand Index: 0.092\n",
      "Adjusted Mutual Information: 0.249\n",
      "**************************************************\n",
      "Params:  {'vec__analyzer': 'word', 'vec__min_df': 0.05, 'vec__ngram_range': (1, 2), 'model__n_clusters': 8, 'vec__tokenizer': <function lemmatizer at 0x7f9e7614be18>}\n",
      "Silhouette Coefficient: 0.997\n",
      "Homogeneity: 0.137\n",
      "Completeness: 0.503\n",
      "V-measure: 0.215\n",
      "Adjusted Rand Index: 0.032\n",
      "Adjusted Mutual Information: 0.214\n",
      "**************************************************\n",
      "Params:  {'vec__analyzer': 'char', 'vec__min_df': 0.05, 'vec__ngram_range': (1, 2), 'model__n_clusters': 8, 'vec__tokenizer': <function lemmatizer at 0x7f9e7614be18>}\n",
      "Silhouette Coefficient: 0.080\n",
      "Homogeneity: 0.193\n",
      "Completeness: 0.300\n",
      "V-measure: 0.235\n",
      "Adjusted Rand Index: 0.084\n",
      "Adjusted Mutual Information: 0.235\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "fixed_params = {\"vec__tokenizer\": lemmatizer}\n",
    "params = {\n",
    "    \"model__n_clusters\": [2, 4, 6, 8],\n",
    "    \"vec__ngram_range\": [(1, 3), (1, 2)],\n",
    "    \"vec__min_df\": [.02, .05],\n",
    "    \"vec__analyzer\": [\"word\", \"char\"]\n",
    "}\n",
    "cluster_grid_search(cluster.MiniBatchKMeans, TfidfVectorizer, params, fixed_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model class: <class 'sklearn.cluster._kmeans.MiniBatchKMeans'>\n",
      "Vectorizer class: <class 'sklearn.feature_extraction.text.CountVectorizer'>\n",
      "Params:  {'vec__analyzer': 'word', 'vec__min_df': 0.02, 'vec__ngram_range': (1, 3), 'model__n_clusters': 2, 'vec__tokenizer': <function lemmatizer at 0x7f9e7614be18>}\n",
      "Silhouette Coefficient: 0.686\n",
      "Homogeneity: 0.069\n",
      "Completeness: 0.917\n",
      "V-measure: 0.129\n",
      "Adjusted Rand Index: 0.022\n",
      "Adjusted Mutual Information: 0.129\n",
      "**************************************************\n",
      "Params:  {'vec__analyzer': 'char', 'vec__min_df': 0.02, 'vec__ngram_range': (1, 3), 'model__n_clusters': 2, 'vec__tokenizer': <function lemmatizer at 0x7f9e7614be18>}\n",
      "Silhouette Coefficient: 0.180\n",
      "Homogeneity: 0.036\n",
      "Completeness: 0.175\n",
      "V-measure: 0.060\n",
      "Adjusted Rand Index: 0.031\n",
      "Adjusted Mutual Information: 0.060\n",
      "**************************************************\n",
      "Params:  {'vec__analyzer': 'word', 'vec__min_df': 0.05, 'vec__ngram_range': (1, 3), 'model__n_clusters': 2, 'vec__tokenizer': <function lemmatizer at 0x7f9e7614be18>}\n",
      "Silhouette Coefficient: 0.837\n",
      "Homogeneity: 0.069\n",
      "Completeness: 0.917\n",
      "V-measure: 0.129\n",
      "Adjusted Rand Index: 0.022\n",
      "Adjusted Mutual Information: 0.129\n",
      "**************************************************\n",
      "Params:  {'vec__analyzer': 'char', 'vec__min_df': 0.05, 'vec__ngram_range': (1, 3), 'model__n_clusters': 2, 'vec__tokenizer': <function lemmatizer at 0x7f9e7614be18>}\n",
      "Silhouette Coefficient: 0.194\n",
      "Homogeneity: 0.034\n",
      "Completeness: 0.165\n",
      "V-measure: 0.057\n",
      "Adjusted Rand Index: 0.029\n",
      "Adjusted Mutual Information: 0.057\n",
      "**************************************************\n",
      "Params:  {'vec__analyzer': 'word', 'vec__min_df': 0.02, 'vec__ngram_range': (1, 2), 'model__n_clusters': 2, 'vec__tokenizer': <function lemmatizer at 0x7f9e7614be18>}\n",
      "Silhouette Coefficient: 0.686\n",
      "Homogeneity: 0.069\n",
      "Completeness: 0.917\n",
      "V-measure: 0.129\n",
      "Adjusted Rand Index: 0.022\n",
      "Adjusted Mutual Information: 0.129\n",
      "**************************************************\n",
      "Params:  {'vec__analyzer': 'char', 'vec__min_df': 0.02, 'vec__ngram_range': (1, 2), 'model__n_clusters': 2, 'vec__tokenizer': <function lemmatizer at 0x7f9e7614be18>}\n",
      "Silhouette Coefficient: 0.195\n",
      "Homogeneity: 0.025\n",
      "Completeness: 0.135\n",
      "V-measure: 0.041\n",
      "Adjusted Rand Index: 0.013\n",
      "Adjusted Mutual Information: 0.041\n",
      "**************************************************\n",
      "Params:  {'vec__analyzer': 'word', 'vec__min_df': 0.05, 'vec__ngram_range': (1, 2), 'model__n_clusters': 2, 'vec__tokenizer': <function lemmatizer at 0x7f9e7614be18>}\n",
      "Silhouette Coefficient: 0.837\n",
      "Homogeneity: 0.069\n",
      "Completeness: 0.917\n",
      "V-measure: 0.129\n",
      "Adjusted Rand Index: 0.022\n",
      "Adjusted Mutual Information: 0.129\n",
      "**************************************************\n",
      "Params:  {'vec__analyzer': 'char', 'vec__min_df': 0.05, 'vec__ngram_range': (1, 2), 'model__n_clusters': 2, 'vec__tokenizer': <function lemmatizer at 0x7f9e7614be18>}\n",
      "Silhouette Coefficient: 0.187\n",
      "Homogeneity: 0.027\n",
      "Completeness: 0.139\n",
      "V-measure: 0.045\n",
      "Adjusted Rand Index: 0.011\n",
      "Adjusted Mutual Information: 0.045\n",
      "**************************************************\n",
      "Params:  {'vec__analyzer': 'word', 'vec__min_df': 0.02, 'vec__ngram_range': (1, 3), 'model__n_clusters': 4, 'vec__tokenizer': <function lemmatizer at 0x7f9e7614be18>}\n",
      "Silhouette Coefficient: 0.617\n",
      "Homogeneity: 0.099\n",
      "Completeness: 0.595\n",
      "V-measure: 0.170\n",
      "Adjusted Rand Index: 0.030\n",
      "Adjusted Mutual Information: 0.170\n",
      "**************************************************\n",
      "Params:  {'vec__analyzer': 'char', 'vec__min_df': 0.02, 'vec__ngram_range': (1, 3), 'model__n_clusters': 4, 'vec__tokenizer': <function lemmatizer at 0x7f9e7614be18>}\n",
      "Silhouette Coefficient: 0.181\n",
      "Homogeneity: 0.105\n",
      "Completeness: 0.309\n",
      "V-measure: 0.156\n",
      "Adjusted Rand Index: 0.053\n",
      "Adjusted Mutual Information: 0.156\n",
      "**************************************************\n",
      "Params:  {'vec__analyzer': 'word', 'vec__min_df': 0.05, 'vec__ngram_range': (1, 3), 'model__n_clusters': 4, 'vec__tokenizer': <function lemmatizer at 0x7f9e7614be18>}\n",
      "Silhouette Coefficient: 0.940\n",
      "Homogeneity: 0.098\n",
      "Completeness: 0.435\n",
      "V-measure: 0.160\n",
      "Adjusted Rand Index: 0.026\n",
      "Adjusted Mutual Information: 0.159\n",
      "**************************************************\n",
      "Params:  {'vec__analyzer': 'char', 'vec__min_df': 0.05, 'vec__ngram_range': (1, 3), 'model__n_clusters': 4, 'vec__tokenizer': <function lemmatizer at 0x7f9e7614be18>}\n",
      "Silhouette Coefficient: 0.196\n",
      "Homogeneity: 0.095\n",
      "Completeness: 0.271\n",
      "V-measure: 0.141\n",
      "Adjusted Rand Index: 0.044\n",
      "Adjusted Mutual Information: 0.141\n",
      "**************************************************\n",
      "Params:  {'vec__analyzer': 'word', 'vec__min_df': 0.02, 'vec__ngram_range': (1, 2), 'model__n_clusters': 4, 'vec__tokenizer': <function lemmatizer at 0x7f9e7614be18>}\n",
      "Silhouette Coefficient: 0.616\n",
      "Homogeneity: 0.103\n",
      "Completeness: 0.621\n",
      "V-measure: 0.176\n",
      "Adjusted Rand Index: 0.024\n",
      "Adjusted Mutual Information: 0.176\n",
      "**************************************************\n",
      "Params:  {'vec__analyzer': 'char', 'vec__min_df': 0.02, 'vec__ngram_range': (1, 2), 'model__n_clusters': 4, 'vec__tokenizer': <function lemmatizer at 0x7f9e7614be18>}\n",
      "Silhouette Coefficient: 0.112\n",
      "Homogeneity: 0.088\n",
      "Completeness: 0.230\n",
      "V-measure: 0.128\n",
      "Adjusted Rand Index: 0.055\n",
      "Adjusted Mutual Information: 0.127\n",
      "**************************************************\n",
      "Params:  {'vec__analyzer': 'word', 'vec__min_df': 0.05, 'vec__ngram_range': (1, 2), 'model__n_clusters': 4, 'vec__tokenizer': <function lemmatizer at 0x7f9e7614be18>}\n",
      "Silhouette Coefficient: 0.940\n",
      "Homogeneity: 0.098\n",
      "Completeness: 0.435\n",
      "V-measure: 0.160\n",
      "Adjusted Rand Index: 0.026\n",
      "Adjusted Mutual Information: 0.159\n",
      "**************************************************\n",
      "Params:  {'vec__analyzer': 'char', 'vec__min_df': 0.05, 'vec__ngram_range': (1, 2), 'model__n_clusters': 4, 'vec__tokenizer': <function lemmatizer at 0x7f9e7614be18>}\n",
      "Silhouette Coefficient: 0.140\n",
      "Homogeneity: 0.136\n",
      "Completeness: 0.353\n",
      "V-measure: 0.196\n",
      "Adjusted Rand Index: 0.088\n",
      "Adjusted Mutual Information: 0.196\n",
      "**************************************************\n",
      "Params:  {'vec__analyzer': 'word', 'vec__min_df': 0.02, 'vec__ngram_range': (1, 3), 'model__n_clusters': 6, 'vec__tokenizer': <function lemmatizer at 0x7f9e7614be18>}\n",
      "Silhouette Coefficient: 0.735\n",
      "Homogeneity: 0.123\n",
      "Completeness: 0.405\n",
      "V-measure: 0.189\n",
      "Adjusted Rand Index: 0.032\n",
      "Adjusted Mutual Information: 0.189\n",
      "**************************************************\n",
      "Params:  {'vec__analyzer': 'char', 'vec__min_df': 0.02, 'vec__ngram_range': (1, 3), 'model__n_clusters': 6, 'vec__tokenizer': <function lemmatizer at 0x7f9e7614be18>}\n",
      "Silhouette Coefficient: 0.118\n",
      "Homogeneity: 0.179\n",
      "Completeness: 0.369\n",
      "V-measure: 0.241\n",
      "Adjusted Rand Index: 0.108\n",
      "Adjusted Mutual Information: 0.241\n",
      "**************************************************\n",
      "Params:  {'vec__analyzer': 'word', 'vec__min_df': 0.05, 'vec__ngram_range': (1, 3), 'model__n_clusters': 6, 'vec__tokenizer': <function lemmatizer at 0x7f9e7614be18>}\n",
      "Silhouette Coefficient: 0.974\n",
      "Homogeneity: 0.123\n",
      "Completeness: 0.487\n",
      "V-measure: 0.196\n",
      "Adjusted Rand Index: 0.030\n",
      "Adjusted Mutual Information: 0.196\n",
      "**************************************************\n",
      "Params:  {'vec__analyzer': 'char', 'vec__min_df': 0.05, 'vec__ngram_range': (1, 3), 'model__n_clusters': 6, 'vec__tokenizer': <function lemmatizer at 0x7f9e7614be18>}\n",
      "Silhouette Coefficient: 0.060\n",
      "Homogeneity: 0.143\n",
      "Completeness: 0.261\n",
      "V-measure: 0.185\n",
      "Adjusted Rand Index: 0.076\n",
      "Adjusted Mutual Information: 0.185\n",
      "**************************************************\n",
      "Params:  {'vec__analyzer': 'word', 'vec__min_df': 0.02, 'vec__ngram_range': (1, 2), 'model__n_clusters': 6, 'vec__tokenizer': <function lemmatizer at 0x7f9e7614be18>}\n",
      "Silhouette Coefficient: 0.697\n",
      "Homogeneity: 0.110\n",
      "Completeness: 0.376\n",
      "V-measure: 0.170\n",
      "Adjusted Rand Index: 0.029\n",
      "Adjusted Mutual Information: 0.170\n",
      "**************************************************\n",
      "Params:  {'vec__analyzer': 'char', 'vec__min_df': 0.02, 'vec__ngram_range': (1, 2), 'model__n_clusters': 6, 'vec__tokenizer': <function lemmatizer at 0x7f9e7614be18>}\n",
      "Silhouette Coefficient: 0.076\n",
      "Homogeneity: 0.131\n",
      "Completeness: 0.235\n",
      "V-measure: 0.168\n",
      "Adjusted Rand Index: 0.059\n",
      "Adjusted Mutual Information: 0.168\n",
      "**************************************************\n",
      "Params:  {'vec__analyzer': 'word', 'vec__min_df': 0.05, 'vec__ngram_range': (1, 2), 'model__n_clusters': 6, 'vec__tokenizer': <function lemmatizer at 0x7f9e7614be18>}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Coefficient: 0.967\n",
      "Homogeneity: 0.115\n",
      "Completeness: 0.469\n",
      "V-measure: 0.184\n",
      "Adjusted Rand Index: 0.026\n",
      "Adjusted Mutual Information: 0.184\n",
      "**************************************************\n",
      "Params:  {'vec__analyzer': 'char', 'vec__min_df': 0.05, 'vec__ngram_range': (1, 2), 'model__n_clusters': 6, 'vec__tokenizer': <function lemmatizer at 0x7f9e7614be18>}\n",
      "Silhouette Coefficient: 0.096\n",
      "Homogeneity: 0.147\n",
      "Completeness: 0.278\n",
      "V-measure: 0.193\n",
      "Adjusted Rand Index: 0.093\n",
      "Adjusted Mutual Information: 0.192\n",
      "**************************************************\n",
      "Params:  {'vec__analyzer': 'word', 'vec__min_df': 0.02, 'vec__ngram_range': (1, 3), 'model__n_clusters': 8, 'vec__tokenizer': <function lemmatizer at 0x7f9e7614be18>}\n",
      "Silhouette Coefficient: 0.725\n",
      "Homogeneity: 0.131\n",
      "Completeness: 0.440\n",
      "V-measure: 0.202\n",
      "Adjusted Rand Index: 0.020\n",
      "Adjusted Mutual Information: 0.202\n",
      "**************************************************\n",
      "Params:  {'vec__analyzer': 'char', 'vec__min_df': 0.02, 'vec__ngram_range': (1, 3), 'model__n_clusters': 8, 'vec__tokenizer': <function lemmatizer at 0x7f9e7614be18>}\n",
      "Silhouette Coefficient: 0.073\n",
      "Homogeneity: 0.172\n",
      "Completeness: 0.284\n",
      "V-measure: 0.214\n",
      "Adjusted Rand Index: 0.107\n",
      "Adjusted Mutual Information: 0.214\n",
      "**************************************************\n",
      "Params:  {'vec__analyzer': 'word', 'vec__min_df': 0.05, 'vec__ngram_range': (1, 3), 'model__n_clusters': 8, 'vec__tokenizer': <function lemmatizer at 0x7f9e7614be18>}\n",
      "Silhouette Coefficient: 0.994\n",
      "Homogeneity: 0.137\n",
      "Completeness: 0.503\n",
      "V-measure: 0.215\n",
      "Adjusted Rand Index: 0.032\n",
      "Adjusted Mutual Information: 0.214\n",
      "**************************************************\n",
      "Params:  {'vec__analyzer': 'char', 'vec__min_df': 0.05, 'vec__ngram_range': (1, 3), 'model__n_clusters': 8, 'vec__tokenizer': <function lemmatizer at 0x7f9e7614be18>}\n",
      "Silhouette Coefficient: 0.094\n",
      "Homogeneity: 0.191\n",
      "Completeness: 0.311\n",
      "V-measure: 0.237\n",
      "Adjusted Rand Index: 0.112\n",
      "Adjusted Mutual Information: 0.236\n",
      "**************************************************\n",
      "Params:  {'vec__analyzer': 'word', 'vec__min_df': 0.02, 'vec__ngram_range': (1, 2), 'model__n_clusters': 8, 'vec__tokenizer': <function lemmatizer at 0x7f9e7614be18>}\n",
      "Silhouette Coefficient: 0.773\n",
      "Homogeneity: 0.131\n",
      "Completeness: 0.382\n",
      "V-measure: 0.195\n",
      "Adjusted Rand Index: 0.029\n",
      "Adjusted Mutual Information: 0.194\n",
      "**************************************************\n",
      "Params:  {'vec__analyzer': 'char', 'vec__min_df': 0.02, 'vec__ngram_range': (1, 2), 'model__n_clusters': 8, 'vec__tokenizer': <function lemmatizer at 0x7f9e7614be18>}\n",
      "Silhouette Coefficient: 0.058\n",
      "Homogeneity: 0.166\n",
      "Completeness: 0.262\n",
      "V-measure: 0.203\n",
      "Adjusted Rand Index: 0.091\n",
      "Adjusted Mutual Information: 0.202\n",
      "**************************************************\n",
      "Params:  {'vec__analyzer': 'word', 'vec__min_df': 0.05, 'vec__ngram_range': (1, 2), 'model__n_clusters': 8, 'vec__tokenizer': <function lemmatizer at 0x7f9e7614be18>}\n",
      "Silhouette Coefficient: 0.994\n",
      "Homogeneity: 0.137\n",
      "Completeness: 0.503\n",
      "V-measure: 0.215\n",
      "Adjusted Rand Index: 0.032\n",
      "Adjusted Mutual Information: 0.214\n",
      "**************************************************\n",
      "Params:  {'vec__analyzer': 'char', 'vec__min_df': 0.05, 'vec__ngram_range': (1, 2), 'model__n_clusters': 8, 'vec__tokenizer': <function lemmatizer at 0x7f9e7614be18>}\n",
      "Silhouette Coefficient: 0.083\n",
      "Homogeneity: 0.179\n",
      "Completeness: 0.283\n",
      "V-measure: 0.219\n",
      "Adjusted Rand Index: 0.103\n",
      "Adjusted Mutual Information: 0.219\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "cluster_grid_search(cluster.MiniBatchKMeans, CountVectorizer, params, fixed_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Судя по выводу метрик, TfIdf vectorizer дает лучший результат"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2\n",
    "На нескольких алгоритмах кластеризации проверьте, какое матричное разложение (TruncatedSVD или NMF) работает лучше для кластеризации. (3 балла)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF, TruncatedSVD\n",
    "from sklearn.cluster import AgglomerativeClustering, MeanShift, SpectralClustering, DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model class: <class 'sklearn.cluster._agglomerative.AgglomerativeClustering'>\n",
      "Vectorizer class: <class 'sklearn.feature_extraction.text.TfidfVectorizer'>\n",
      "Params:  {'vec__analyzer': 'word', 'vec__min_df': 0.02, 'vec__ngram_range': (1, 3), 'model__linkage': 'ward', 'vec__tokenizer': <function lemmatizer at 0x7f815f24cea0>, 'model__n_clusters': 1100, 'dec__n_components': 50}\n"
     ]
    }
   ],
   "source": [
    "fixed_params = {\"vec__tokenizer\": lemmatizer,\n",
    "                \"model__n_clusters\": 1100,\n",
    "                \"dec__n_components\": 50}\n",
    "params = {\n",
    "    \"model__linkage\": [\"ward\", \"complete\", \"average\", \"single\"],\n",
    "    \"vec__ngram_range\": [(1, 3), (1, 2)],\n",
    "    \"vec__min_df\": [.02, .05],\n",
    "    \"vec__analyzer\": [\"word\", \"char\"]\n",
    "}\n",
    "cluster_grid_search(AgglomerativeClustering, TfidfVectorizer, NMF, params, fixed_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Честно говорю, не доделал. Оцените, пожалуйста, что есть. Спасибо!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
